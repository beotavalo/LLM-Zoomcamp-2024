{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Failed to load OpenAI API key.\n"]}],"source":["import os\n","\n","# Access the environment variable\n","openai_api_key = os.getenv('OPENAI_API_KEY')\n","\n","# Check if the API key is correctly loaded\n","if openai_api_key:\n","    print(\"OpenAI API key loaded successfully.\")\n","else:\n","    print(\"Failed to load OpenAI API key.\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/codespace/.python/current/bin/python\n"]}],"source":["!which python"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["openai 0.28.0\n"]}],"source":["!openai -V"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of completion tokens: 254\n"]}],"source":["import openai\n","import os\n","\n","# Configure OpenAI client with your API key\n","openai.api_key = api_key\n","\n","# Example prompt to test\n","prompt = \"What's the formula for energy?\"\n","\n","# Request to OpenAI API for text completion\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-4o\",  # Adjust model name as per your setup\n","    messages=[\n","        {\"role\": \"user\", \"content\": prompt}\n","    ],\n","    temperature=0.0\n",")\n","\n","# Extract completion tokens from the response\n","if 'choices' in response and len(response['choices']) > 0:\n","    messages = response['choices'][0]['message']['content']\n","    num_tokens = len(messages.split())\n","    print(\"Number of completion tokens:\", num_tokens)\n","else:\n","    print(\"No valid response received from OpenAI.\")\n","\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["\"The formula for energy can vary depending on the context and the type of energy being considered. Here are a few common formulas:\\n\\n1. **Kinetic Energy (KE)**:\\n   \\\\[\\n   KE = \\\\frac{1}{2}mv^2\\n   \\\\]\\n   where \\\\( m \\\\) is the mass of the object and \\\\( v \\\\) is its velocity.\\n\\n2. **Potential Energy (PE)**:\\n   - **Gravitational Potential Energy**:\\n     \\\\[\\n     PE = mgh\\n     \\\\]\\n     where \\\\( m \\\\) is the mass, \\\\( g \\\\) is the acceleration due to gravity, and \\\\( h \\\\) is the height above a reference point.\\n   - **Elastic Potential Energy** (for a spring):\\n     \\\\[\\n     PE = \\\\frac{1}{2}kx^2\\n     \\\\]\\n     where \\\\( k \\\\) is the spring constant and \\\\( x \\\\) is the displacement from the equilibrium position.\\n\\n3. **Thermal Energy**:\\n   \\\\[\\n   Q = mc\\\\Delta T\\n   \\\\]\\n   where \\\\( Q \\\\) is the heat energy, \\\\( m \\\\) is the mass, \\\\( c \\\\) is the specific heat capacity, and \\\\( \\\\Delta T \\\\) is the change in temperature.\\n\\n4. **Electrical Energy**:\\n   \\\\[\\n   E = VIt\\n   \\\\]\\n   where \\\\( E \\\\) is the energy, \\\\( V \\\\) is the voltage, \\\\( I \\\\) is the current, and \\\\( t \\\\) is the time.\\n\\n5. **Einstein's Mass-Energy Equivalence**:\\n   \\\\[\\n   E = mc^2\\n   \\\\]\\n   where \\\\( E \\\\) is the energy, \\\\( m \\\\) is the mass, and \\\\( c \\\\) is the speed of light in a vacuum.\\n\\nEach of these formulas applies to different scenarios and types of energy, so the appropriate formula depends on the specific situation you are dealing with.\""]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["response['choices'][0].message.content"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting regex>=2022.1.18 (from tiktoken)\n","  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: regex, tiktoken\n","Successfully installed regex-2024.5.15 tiktoken-0.7.0\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of tokens in the query is: 401\n"]}],"source":["import tiktoken\n","\n","# Initialize the encoding for the GPT-4 model\n","encoding = tiktoken.encoding_for_model(\"gpt-4\")\n","\n","# Encode the query to get the tokens\n","tokens = encoding.encode(response['choices'][0].message.content)\n","\n","# Count the number of tokens\n","num_tokens = len(tokens)\n","\n","print(f\"The number of tokens in the query is: {num_tokens}\")"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (3.14.0)\n","Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n","  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Collecting safetensors>=0.4.1 (from transformers)\n","  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting tokenizers<0.20,>=0.19 (from transformers)\n","  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.23.4 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.3\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install transformers "]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of completion tokens: 478\n"]}],"source":["import openai\n","from transformers import GPT2Tokenizer\n","\n","# Set your OpenAI API key\n","#api_key = \"your_openai_api_key_here\"  # Replace with your actual API key\n","\n","# Configure OpenAI client with your API key\n","openai.api_key = api_key\n","\n","# Initialize GPT-2 tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")  # Use appropriate tokenizer based on your model\n","\n","# Example prompt to test\n","prompt = \"What's the formula for energy?\"\n","\n","# Request to OpenAI API for text completion\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-4o\",  # Adjust model name to ollama-gemma2b or your specific model\n","    messages=[\n","        {\"role\": \"user\", \"content\": prompt}\n","    ],\n","    temperature=0.0\n",")\n","\n","# Extract completion tokens from the response using tokenizer\n","if 'choices' in response and len(response['choices']) > 0:\n","    messages = response['choices'][0]['message']['content']\n","    tokenized_messages = tokenizer.tokenize(messages)\n","    num_tokens = len(tokenized_messages)\n","    print(\"Number of completion tokens:\", num_tokens)\n","else:\n","    print(\"No valid response received from OpenAI.\")\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["promt_hw = '''Sure, the formula for energy is:\n","\n","**E = K + U**\n","\n","Where:\n","\n","* **E** is the energy in joules (J)\n","* **K** is the kinetic energy in joules (J)\n","* **U** is the potential energy in joules (J)\n","\n","**Kinetic energy** measures the energy of motion, and is given by the formula:\n","\n","**K = (1/2)mv²**\n","\n","Where:\n","\n","* **m** is the mass in kilograms (kg)\n","* **v** is the velocity in meters per second (m/s)\n","\n","**Potential energy** measures the energy of position, and is given by the formula:\n","\n","**U = mgh**\n","\n","Where:\n","\n","* **m** is the mass in kilograms (kg)\n","* **g** is the acceleration due to gravity in meters per second squared (m/s²)\n","* **h** is the height in meters (m)\n","\n","The total energy is the sum of the kinetic and potential energies:\n","\n","**E = K + U**\n","\n","This formula can be used to calculate the energy of an object at rest, or of an object in motion, or of an object at a \n","given height.'''\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of tokens in the query is: 237\n"]}],"source":["import tiktoken\n","\n","# Initialize the encoding for the GPT-4 model\n","encoding = tiktoken.encoding_for_model(\"gpt-4\")\n","\n","# Encode the query to get the tokens\n","tokens = encoding.encode(promt_hw)\n","\n","# Count the number of tokens\n","num_tokens = len(tokens)\n","\n","print(f\"The number of tokens in the query is: {num_tokens}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
